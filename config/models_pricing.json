{
    "claude-haiku-4-5-20251001": {
        "provider": "anthropic",
        "name": "Claude Haiku 4.5",
        "capabilities": ["chat", "reasoning", "code", "analysis"],
        "context_window": 200000,
        "max_output_tokens": 64000,
        "cost_input": 1.00,
        "cost_output": 5.00,
        "speed": "fast",
        "quality": "high",
        "use_cases": ["fast responses", "cost-effective reasoning", "general tasks"]
    },
    "claude-sonnet-4-5-20250929": {
        "provider": "anthropic",
        "name": "Claude Sonnet 4.5",
        "capabilities": ["chat", "reasoning", "code", "analysis", "long-context"],
        "context_window": 200000,
        "max_output_tokens": 64000,
        "cost_input": 3.00,
        "cost_output": 15.00,
        "speed": "medium",
        "quality": "highest",
        "use_cases": ["complex reasoning", "code generation", "deep analysis", "creative writing"]
    },
    "claude-sonnet-4-20250514": {
        "provider": "anthropic",
        "name": "Claude Sonnet 4",
        "capabilities": ["chat", "reasoning", "code", "analysis", "long-context"],
        "context_window": 200000,
        "max_output_tokens": 64000,
        "cost_input": 3.00,
        "cost_output": 15.00,
        "speed": "medium",
        "quality": "highest",
        "use_cases": ["complex reasoning", "code generation", "deep analysis"]
    },
    "claude-3-7-sonnet-20250219": {
        "provider": "anthropic",
        "name": "Claude 3.7 Sonnet",
        "capabilities": ["chat", "reasoning", "code", "analysis"],
        "context_window": 200000,
        "max_output_tokens": 64000,
        "cost_input": 3.00,
        "cost_output": 15.00,
        "speed": "medium",
        "quality": "high",
        "use_cases": ["general tasks", "coding", "analysis"]
    },
    "claude-3-5-haiku-20241022": {
        "provider": "anthropic",
        "name": "Claude 3.5 Haiku",
        "capabilities": ["chat", "code", "simple-tasks"],
        "context_window": 200000,
        "max_output_tokens": 8000,
        "cost_input": 0.80,
        "cost_output": 4.00,
        "speed": "fast",
        "quality": "good",
        "use_cases": ["simple tasks", "quick responses", "cost-effective operations"]
    },

    "gpt-5-2025-08-07": {
        "provider": "openai",
        "name": "GPT-5",
        "capabilities": ["chat", "reasoning", "code", "analysis", "long-context"],
        "context_window": 400000,
        "max_output_tokens": 128000,
        "cost_input": 1.25,
        "cost_output": 10.00,
        "speed": "medium",
        "quality": "highest",
        "use_cases": ["complex reasoning", "code generation", "long documents", "analysis"]
    },
    "gpt-4.1-2025-04-14": {
        "provider": "openai",
        "name": "GPT-4.1",
        "capabilities": ["chat", "code", "analysis", "long-context"],
        "context_window": 1000000,
        "max_output_tokens": 32000,
        "cost_input": 2.00,
        "cost_output": 8.00,
        "speed": "medium",
        "quality": "high",
        "use_cases": ["very long documents", "large codebases", "extensive context"]
    },
    "o4-mini-2025-04-16": {
        "provider": "openai",
        "name": "O4 Mini",
        "capabilities": ["reasoning", "math", "code", "science"],
        "context_window": 200000,
        "max_output_tokens": 100000,
        "cost_input": 1.10,
        "cost_output": 4.40,
        "speed": "medium",
        "quality": "high",
        "use_cases": ["reasoning tasks", "math problems", "scientific analysis"]
    },
    "gpt-5-mini-2025-08-07": {
        "provider": "openai",
        "name": "GPT-5 Mini",
        "capabilities": ["chat", "reasoning", "code", "analysis"],
        "context_window": 400000,
        "max_output_tokens": 128000,
        "cost_input": 0.25,
        "cost_output": 2.00,
        "speed": "fast",
        "quality": "high",
        "use_cases": ["cost-effective reasoning", "general tasks", "high volume"]
    },
    "gpt-5-nano-2025-08-07": {
        "provider": "openai",
        "name": "GPT-5 Nano",
        "capabilities": ["chat", "reasoning", "simple-tasks"],
        "context_window": 400000,
        "max_output_tokens": 128000,
        "cost_input": 0.05,
        "cost_output": 0.40,
        "speed": "fast",
        "quality": "good",
        "use_cases": ["ultra-low-cost tasks", "high volume operations", "simple queries"]
    },
    "gpt-4o-2024-11-20": {
        "provider": "openai",
        "name": "GPT-4o",
        "capabilities": ["chat", "vision", "code", "multimodal"],
        "context_window": 128000,
        "max_output_tokens": 16000,
        "cost_input": 2.50,
        "cost_output": 1.25,
        "speed": "medium",
        "quality": "high",
        "use_cases": ["multimodal tasks", "vision", "image analysis"]
    },
    "gpt-5-pro-2025-10-06": {
        "provider": "openai",
        "name": "GPT-5 Pro",
        "capabilities": ["chat", "reasoning", "code", "analysis", "long-context"],
        "context_window": 400000,
        "max_output_tokens": 272000,
        "cost_input": 1.25,
        "cost_output": 120.00,
        "speed": "slow",
        "quality": "highest",
        "use_cases": ["highest quality output", "critical tasks", "extensive responses"]
    },
    "o4-mini-deep-research-2025-06-26": {
        "provider": "openai",
        "name": "O4 Mini Deep Research",
        "capabilities": ["reasoning", "research", "analysis", "science", "math"],
        "context_window": 200000,
        "max_output_tokens": 100000,
        "cost_input": 2.00,
        "cost_output": 8.00,
        "speed": "slow",
        "quality": "highest",
        "use_cases": ["deep research", "scientific analysis", "complex problem solving"]
    },

    "palmyra-x5": {
        "provider": "writer",
        "name": "Palmyra X5",
        "capabilities": ["chat", "code", "analysis", "long-context"],
        "context_window": 1000000,
        "max_output_tokens": 32000,
        "cost_input": 0.60,
        "cost_output": 6.00,
        "speed": "medium",
        "quality": "high",
        "use_cases": ["cost-effective long context", "large documents", "general tasks"]
    },
    "palmyra-x4": {
        "provider": "writer",
        "name": "Palmyra X4",
        "capabilities": ["chat", "code", "analysis"],
        "context_window": 128000,
        "max_output_tokens": 32000,
        "cost_input": 2.50,
        "cost_output": 10.00,
        "speed": "medium",
        "quality": "high",
        "use_cases": ["general tasks", "coding", "analysis"]
    },
    "palmyra-fin": {
        "provider": "writer",
        "name": "Palmyra Finance",
        "capabilities": ["chat", "finance", "analysis"],
        "context_window": 128000,
        "max_output_tokens": 32000,
        "cost_input": 5.00,
        "cost_output": 12.00,
        "speed": "medium",
        "quality": "high",
        "use_cases": ["financial analysis", "market research", "business intelligence"]
    },
    "palmyra-med": {
        "provider": "writer",
        "name": "Palmyra Medical",
        "capabilities": ["chat", "medical", "analysis"],
        "context_window": 32000,
        "max_output_tokens": 8000,
        "cost_input": 5.00,
        "cost_output": 12.00,
        "speed": "medium",
        "quality": "high",
        "use_cases": ["medical analysis", "healthcare", "clinical documentation"]
    },
    "palmyra-creative": {
        "provider": "writer",
        "name": "Palmyra Creative",
        "capabilities": ["chat", "creative-writing", "content-generation"],
        "context_window": 128000,
        "max_output_tokens": 32000,
        "cost_input": 5.00,
        "cost_output": 12.00,
        "speed": "medium",
        "quality": "high",
        "use_cases": ["creative writing", "content creation", "marketing copy"]
    },

    "qwen3:4b": {
        "provider": "ollama",
        "name": "Qwen 3 4B",
        "capabilities": ["chat", "code", "reasoning", "local"],
        "context_window": 260000,
        "max_output_tokens": 128000,
        "cost_input": 0.00,
        "cost_output": 0.00,
        "speed": "fast",
        "quality": "good",
        "use_cases": ["local deployment", "privacy", "no API costs", "offline usage"]
    },
    "llama3.1:latest": {
        "provider": "ollama",
        "name": "Llama 3.1",
        "capabilities": ["chat", "code", "reasoning", "local"],
        "context_window": 131000,
        "max_output_tokens": 128000,
        "cost_input": 0.00,
        "cost_output": 0.00,
        "speed": "medium",
        "quality": "good",
        "use_cases": ["local deployment", "privacy", "no API costs", "offline usage"]
    },
    "gemma3n:e4b": {
        "provider": "ollama",
        "name": "Gemma 3N 4B",
        "capabilities": ["chat", "simple-tasks", "local"],
        "context_window": 32000,
        "max_output_tokens": 8000,
        "cost_input": 0.00,
        "cost_output": 0.00,
        "speed": "fast",
        "quality": "good",
        "use_cases": ["local deployment", "simple chat", "no tool support"]
    }
}
